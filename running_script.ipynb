{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbd370bf-d7b7-4237-a07d-9c22826173d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running script 4.1 Latest version with seed 42\n",
      "CUDA is not available. Setting epochs to 100.\n",
      "crop_size:  (1, 128, 128)\n",
      "Loading PSZ2 data...\n",
      "No exact‐byte duplicates found.\n",
      "train_idx test_idx lengths: 140 36\n",
      "Shape of train_images before redistribution: 140 torch.Size([1, 128, 128])\n",
      "Shape of stretched array : (176, 1, 128, 128)\n",
      "Shape of train_images returned from PSZ2: torch.Size([1200, 1, 128, 128])\n",
      "Data loaded: 1200 train images, 208 eval images.\n",
      "Shape of test_images:  torch.Size([208, 1, 128, 128])\n",
      "Test images stats: min=-0.022, max=0.136, mean=0.001, std=0.004\n",
      "Train images stats: min=-0.021, max=0.127, mean=0.000, std=0.001\n",
      "Warning: Train images for class 0 is empty, skipping stats.\n",
      "Warning: Train images for class 1 is empty, skipping stats.\n",
      "Test labels distribution (raw): {0: 104, 1: 104}\n",
      "Test dataset size: 208\n",
      "\n",
      " Training with fold: 5, lr: 0.001, reg: 0.001, lambda: 0\n",
      "Loading PSZ2 data...\n",
      "No exact‐byte duplicates found.\n",
      "train_idx test_idx lengths: 140 36\n",
      "Shape of train_images before redistribution: 140 torch.Size([1, 128, 128])\n",
      "Shape of stretched array : (176, 1, 128, 128)\n",
      "Shape of train_images returned from PSZ2: torch.Size([1200, 1, 128, 128])\n",
      "Data loaded: 1200 train images, 208 eval images.\n",
      "Train labels distribution (raw): {0: 392, 1: 808}\n",
      "Train labels distribution (raw) after possible filtering and augmentation: {0: 392, 1: 808}\n",
      "Shape of train_images before folding T axis:  torch.Size([1200, 1, 128, 128])\n",
      "Shape of train_images after folding T axis:  torch.Size([1200, 1, 128, 128])\n",
      "Shape of train_scat_coeffs directly after computation:  torch.Size([1200, 169, 32, 32])\n",
      "scatdim  torch.Size([169, 32, 32])\n",
      "Summary for ScatterSqueezeNet:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 128, 128]             832\n",
      "       BatchNorm2d-2         [-1, 32, 128, 128]              64\n",
      "         LeakyReLU-3         [-1, 32, 128, 128]               0\n",
      "            Conv2d-4         [-1, 64, 128, 128]          18,496\n",
      "       BatchNorm2d-5         [-1, 64, 128, 128]             128\n",
      "         LeakyReLU-6         [-1, 64, 128, 128]               0\n",
      "         MaxPool2d-7           [-1, 64, 64, 64]               0\n",
      "            Conv2d-8          [-1, 128, 64, 64]         204,928\n",
      "       BatchNorm2d-9          [-1, 128, 64, 64]             256\n",
      "        LeakyReLU-10          [-1, 128, 64, 64]               0\n",
      "           Conv2d-11          [-1, 128, 32, 32]         147,584\n",
      "      BatchNorm2d-12          [-1, 128, 32, 32]             256\n",
      "        LeakyReLU-13          [-1, 128, 32, 32]               0\n",
      "           Conv2d-14          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-15          [-1, 128, 16, 16]             256\n",
      "        LeakyReLU-16          [-1, 128, 16, 16]               0\n",
      "           Conv2d-17            [-1, 128, 8, 8]         147,584\n",
      "      BatchNorm2d-18            [-1, 128, 8, 8]             256\n",
      "        LeakyReLU-19            [-1, 128, 8, 8]               0\n",
      "           Conv2d-20            [-1, 128, 4, 4]         147,584\n",
      "      BatchNorm2d-21            [-1, 128, 4, 4]             256\n",
      "        LeakyReLU-22            [-1, 128, 4, 4]               0\n",
      "           Conv2d-23          [-1, 128, 32, 32]         194,816\n",
      "      BatchNorm2d-24          [-1, 128, 32, 32]             256\n",
      "        LeakyReLU-25          [-1, 128, 32, 32]               0\n",
      "AdaptiveAvgPool2d-26            [-1, 128, 1, 1]               0\n",
      "           Conv2d-27              [-1, 8, 1, 1]           1,024\n",
      "             ReLU-28              [-1, 8, 1, 1]               0\n",
      "           Conv2d-29            [-1, 128, 1, 1]           1,024\n",
      "          Sigmoid-30            [-1, 128, 1, 1]               0\n",
      "          SEBlock-31          [-1, 128, 32, 32]               0\n",
      "           Conv2d-32          [-1, 128, 32, 32]         147,584\n",
      "      BatchNorm2d-33          [-1, 128, 32, 32]             256\n",
      "        LeakyReLU-34          [-1, 128, 32, 32]               0\n",
      "AdaptiveAvgPool2d-35            [-1, 128, 1, 1]               0\n",
      "           Conv2d-36              [-1, 8, 1, 1]           1,024\n",
      "             ReLU-37              [-1, 8, 1, 1]               0\n",
      "           Conv2d-38            [-1, 128, 1, 1]           1,024\n",
      "          Sigmoid-39            [-1, 128, 1, 1]               0\n",
      "          SEBlock-40          [-1, 128, 32, 32]               0\n",
      "           Conv2d-41          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-42          [-1, 128, 16, 16]             256\n",
      "        LeakyReLU-43          [-1, 128, 16, 16]               0\n",
      "AdaptiveAvgPool2d-44            [-1, 128, 1, 1]               0\n",
      "           Conv2d-45              [-1, 8, 1, 1]           1,024\n",
      "             ReLU-46              [-1, 8, 1, 1]               0\n",
      "           Conv2d-47            [-1, 128, 1, 1]           1,024\n",
      "          Sigmoid-48            [-1, 128, 1, 1]               0\n",
      "          SEBlock-49          [-1, 128, 16, 16]               0\n",
      "           Conv2d-50          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-51          [-1, 128, 16, 16]             256\n",
      "        LeakyReLU-52          [-1, 128, 16, 16]               0\n",
      "AdaptiveAvgPool2d-53            [-1, 128, 1, 1]               0\n",
      "           Conv2d-54              [-1, 8, 1, 1]           1,024\n",
      "             ReLU-55              [-1, 8, 1, 1]               0\n",
      "           Conv2d-56            [-1, 128, 1, 1]           1,024\n",
      "          Sigmoid-57            [-1, 128, 1, 1]               0\n",
      "          SEBlock-58          [-1, 128, 16, 16]               0\n",
      "           Conv2d-59            [-1, 128, 8, 8]         147,584\n",
      "      BatchNorm2d-60            [-1, 128, 8, 8]             256\n",
      "        LeakyReLU-61            [-1, 128, 8, 8]               0\n",
      "AdaptiveAvgPool2d-62            [-1, 128, 1, 1]               0\n",
      "           Conv2d-63              [-1, 8, 1, 1]           1,024\n",
      "             ReLU-64              [-1, 8, 1, 1]               0\n",
      "           Conv2d-65            [-1, 128, 1, 1]           1,024\n",
      "          Sigmoid-66            [-1, 128, 1, 1]               0\n",
      "          SEBlock-67            [-1, 128, 8, 8]               0\n",
      "           Conv2d-68            [-1, 128, 8, 8]         147,584\n",
      "      BatchNorm2d-69            [-1, 128, 8, 8]             256\n",
      "        LeakyReLU-70            [-1, 128, 8, 8]               0\n",
      "AdaptiveAvgPool2d-71            [-1, 128, 1, 1]               0\n",
      "           Conv2d-72              [-1, 8, 1, 1]           1,024\n",
      "             ReLU-73              [-1, 8, 1, 1]               0\n",
      "           Conv2d-74            [-1, 128, 1, 1]           1,024\n",
      "          Sigmoid-75            [-1, 128, 1, 1]               0\n",
      "          SEBlock-76            [-1, 128, 8, 8]               0\n",
      "           Conv2d-77            [-1, 128, 4, 4]         147,584\n",
      "      BatchNorm2d-78            [-1, 128, 4, 4]             256\n",
      "        LeakyReLU-79            [-1, 128, 4, 4]               0\n",
      "AdaptiveAvgPool2d-80            [-1, 128, 1, 1]               0\n",
      "           Conv2d-81              [-1, 8, 1, 1]           1,024\n",
      "             ReLU-82              [-1, 8, 1, 1]               0\n",
      "           Conv2d-83            [-1, 128, 1, 1]           1,024\n",
      "          Sigmoid-84            [-1, 128, 1, 1]               0\n",
      "          SEBlock-85            [-1, 128, 4, 4]               0\n",
      "           Linear-86                  [-1, 256]       1,048,832\n",
      "      BatchNorm1d-87                  [-1, 256]             512\n",
      "        LeakyReLU-88                  [-1, 256]               0\n",
      "          Dropout-89                  [-1, 256]               0\n",
      "           Linear-90                  [-1, 256]          65,792\n",
      "      BatchNorm1d-91                  [-1, 256]             512\n",
      "        LeakyReLU-92                  [-1, 256]               0\n",
      "          Dropout-93                  [-1, 256]               0\n",
      "           Linear-94                    [-1, 2]             514\n",
      "================================================================\n",
      "Total params: 3,028,674\n",
      "Trainable params: 3,028,674\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 10816.00\n",
      "Forward/backward pass size (MB): 64.58\n",
      "Params size (MB): 11.55\n",
      "Estimated Total Size (MB): 10892.14\n",
      "----------------------------------------------------------------\n",
      "Using class weights: tensor([3.0612, 1.4851])\n",
      "Training ScatterSqueezeNet model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training ScatterSqueezeNet_[50, 51]_DDPM_120_5_0_0.001_0.001_0:  14%|█▍        | 14/100 [01:55<11:48,  8.24s/it]\n",
      "Training ScatterSqueezeNet_[50, 51]_DDPM_120_5_1_0.001_0.001_0:   4%|▍         | 4/100 [00:34<13:45,  8.59s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scatter_galaxies/4.1.train_classifier.py:971\u001b[39m\n\u001b[32m    969\u001b[39m     outputs = model(scat)\n\u001b[32m    970\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m classifier \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mScatterSqueezeNet\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mScatterSqueezeNet2\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m971\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    973\u001b[39m     outputs = model(images)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib64/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib64/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scatter_galaxies/utils/classifiers.py:771\u001b[39m, in \u001b[36mScatterSqueezeNet.forward\u001b[39m\u001b[34m(self, img, scat)\u001b[39m\n\u001b[32m    769\u001b[39m x_img = \u001b[38;5;28mself\u001b[39m.conv_to_latent_img(x_img)\n\u001b[32m    770\u001b[39m \u001b[38;5;66;03m# Scattering path\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m771\u001b[39m x_scat = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv_to_latent_scat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    772\u001b[39m \u001b[38;5;66;03m# Flatten and concat\u001b[39;00m\n\u001b[32m    773\u001b[39m x_img = x_img.view(x_img.size(\u001b[32m0\u001b[39m), -\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib64/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib64/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib64/python3.11/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib64/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib64/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scatter_galaxies/utils/classifiers.py:663\u001b[39m, in \u001b[36mSEBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    662\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m663\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x * \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib64/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib64/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib64/python3.11/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib64/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib64/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib64/python3.11/site-packages/torch/nn/modules/conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib64/python3.11/site-packages/torch/nn/modules/conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "%run ./4.1.train_classifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c1997f3-bef9-4cf5-9075-3895893bd5aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No files hashed to 1adc95bebe9eea8c112d40cd04ab7a8d75c4f961; check version/class or your hash.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scatter_galaxies/test.py:37\u001b[39m\n\u001b[32m     34\u001b[39m         group.append((fname, crop))\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m group:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo files hashed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhash_target\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m; check version/class or your hash.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# plot them side by side\u001b[39;00m\n\u001b[32m     40\u001b[39m n = \u001b[38;5;28mlen\u001b[39m(group)\n",
      "\u001b[31mRuntimeError\u001b[39m: No files hashed to 1adc95bebe9eea8c112d40cd04ab7a8d75c4f961; check version/class or your hash."
     ]
    }
   ],
   "source": [
    "%run ./test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ce599e-4b44-499b-ae8e-2c9c9440c3d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
